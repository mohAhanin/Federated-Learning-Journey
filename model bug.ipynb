{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0 learning rate: 10.0\n",
      "Client 1 learning rate: 0.0010000000474974513\n",
      "Client 2 learning rate: 0.0010000000474974513\n",
      "Client 3 learning rate: 0.0010000000474974513\n",
      "Client 4 learning rate: 0.0010000000474974513\n",
      "Client 5 learning rate: 0.0010000000474974513\n",
      "Client 6 learning rate: 0.0010000000474974513\n",
      "Client 7 learning rate: 0.0010000000474974513\n",
      "Client 8 learning rate: 0.0010000000474974513\n",
      "Client 9 learning rate: 0.0010000000474974513\n",
      "Warning: Client 0 is an outlier. Potential bug detected.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.stats import ks_2samp, chi2_contingency\n",
    "\n",
    "# Define the metrics function\n",
    "def perform_differential_testing(predictions_i, predictions_j, labels, data_type):\n",
    "    if predictions_i.ndim == 1:\n",
    "        predictions_i = np.expand_dims(predictions_i, axis=1)\n",
    "    if predictions_j.ndim == 1:\n",
    "        predictions_j = np.expand_dims(predictions_j, axis=1)\n",
    "    \n",
    "    pred_class_i = np.argmax(predictions_i, axis=1)\n",
    "    pred_class_j = np.argmax(predictions_j, axis=1)\n",
    "    \n",
    "    Δ_class = np.sum(pred_class_i != pred_class_j)\n",
    "    Δ_score = np.sum(predictions_i != predictions_j)\n",
    "    P_KS = ks_2samp(predictions_i.flatten(), predictions_j.flatten()).pvalue\n",
    "    contingency = np.array([[np.sum((pred_class_i == k) & (pred_class_j == l)) for l in range(10)] for k in range(10)])\n",
    "    contingency += 1  # Add-one smoothing\n",
    "    P_X2 = chi2_contingency(contingency)[1]\n",
    "\n",
    "    return Δ_class, Δ_score, P_KS, P_X2\n",
    "\n",
    "# Custom function to determine if a model is an outlier\n",
    "def is_outlier(metric_data, epsilon=0.2, min_samples=2):\n",
    "    num_points = metric_data.shape[0]\n",
    "    distances = np.linalg.norm(metric_data[:, np.newaxis] - metric_data, axis=2)\n",
    "    neighbors = np.sum(distances < epsilon, axis=1)\n",
    "    outliers = neighbors < min_samples\n",
    "    return \n",
    "\n",
    "# This function calculates the distances between points in the metric_data array and counts the number of neighbors within a specified distance (epsilon).\n",
    "# If the number of neighbors is less than min_samples, the point is considered an outlier.\n",
    "# The is_outlier function is then used in the federated_learning_process to detect outliers:\n",
    "# This approach ensures that the custom DBSCAN-like functionality is used to detect outliers in the federated learning process. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create a simple model\n",
    "def create_model():\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(10, activation='softmax', input_shape=(20,))\n",
    "    ])\n",
    "\n",
    "# Create a federated learning process\n",
    "def model_fn():\n",
    "    model = create_model()\n",
    "    return tff.learning.from_keras_model(\n",
    "        model,\n",
    "        input_spec=(tf.TensorSpec(shape=[None, 20], dtype=tf.float32),\n",
    "                    tf.TensorSpec(shape=[None], dtype=tf.int32)),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "# Simulated federated learning setup\n",
    "def create_fake_model(bug=False):\n",
    "    model = create_model()\n",
    "    if bug:\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=10.0)  # Extremely high learning rate\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)  # Normal learning rate\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Simulated test data on server\n",
    "server_test_data = np.random.random((100, 20))  # 100 samples, 20 features each\n",
    "server_test_labels = np.random.randint(0, 10, 100)  # 100 labels for 10 classes\n",
    "\n",
    "# Simulated client models\n",
    "client_models = [create_fake_model(bug=(i == 0)) for i in range(10)]  # Introduce bug in the first client\n",
    "\n",
    "# Print learning rates of each client model\n",
    "for i, client_model in enumerate(client_models):\n",
    "    print(f\"Client {i} learning rate: {client_model.optimizer.learning_rate.numpy()}\")\n",
    "\n",
    "# Train client models\n",
    "for client_model in client_models:\n",
    "    client_model.fit(server_test_data, server_test_labels, epochs=1, verbose=0)\n",
    "\n",
    "# Perform federated learning process\n",
    "def federated_learning_process(server_model, client_data, epsilon=0.8, min_samples=2):\n",
    "    server_predictions = server_model.predict(server_test_data)\n",
    "    server_predictions = np.argmax(server_predictions, axis=1)\n",
    "\n",
    "    # Store metrics for all clients\n",
    "    metrics_data = []\n",
    "\n",
    "    for client_id, client_model in enumerate(client_data):\n",
    "        client_predictions = client_model.predict(server_test_data)\n",
    "        if client_predictions.ndim == 1:\n",
    "            client_predictions = np.expand_dims(client_predictions, axis=1)\n",
    "        client_predictions = np.argmax(client_predictions, axis=1)  # Ensure correct dimensions\n",
    "        Δ_class, Δ_score, P_KS, P_X2 = perform_differential_testing(\n",
    "            server_predictions, client_predictions, server_test_labels, f\"Client {client_id}\"\n",
    "        )\n",
    "        metrics_data.append([Δ_class, Δ_score, P_KS, P_X2])\n",
    "\n",
    "    # Convert metrics data to numpy array\n",
    "    metrics_data = np.array(metrics_data)\n",
    "    \n",
    "    # Check for outliers\n",
    "    outliers = is_outlier(metrics_data, epsilon=epsilon, min_samples=min_samples)\n",
    "    \n",
    "    for i, outlier in enumerate(outliers):\n",
    "        if outlier:\n",
    "            print(f\"Warning: Client {i} is an outlier. Potential bug detected.\")\n",
    "            return  # Stop the process if an outlier is detected\n",
    "\n",
    "# Perform federated learning process\n",
    "federated_learning_process(server_model=create_fake_model(), client_data=client_models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. **Import Libraries**:\n",
    "   - `tensorflow` for building and training models.\n",
    "   - `numpy` for numerical operations.\n",
    "   - `scipy.stats` for statistical tests.\n",
    "\n",
    "2. **Define the Metrics Function**:\n",
    "   - `perform_differential_testing`: This function compares predictions from two models (`predictions_i` and `predictions_j`) and calculates several metrics:\n",
    "     - `Δ_class`: The number of times the predicted classes differ.\n",
    "     - `Δ_score`: The sum of differences in prediction scores.\n",
    "     - `P_KS`: The p-value from the Kolmogorov-Smirnov test comparing the distributions of the predictions.\n",
    "     - `P_X2`: The p-value from the chi-squared test comparing the contingency table of predicted classes.\n",
    "\n",
    "3. **Custom Outlier Detection Function**:\n",
    "   - `is_outlier`: This function calculates the distances between points in the `metric_data` array and counts the number of neighbors within a specified distance (`epsilon`). If the number of neighbors is less than `min_samples`, the point is considered an outlier.\n",
    "\n",
    "4. **Create a Simple Model**:\n",
    "   - `create_model`: This function creates a simple neural network model with one dense layer using the `softmax` activation function.\n",
    "\n",
    "5. **Create a Federated Learning Process**:\n",
    "   - `model_fn`: This function creates a federated learning model using TensorFlow Federated (TFF).\n",
    "\n",
    "6. **Simulated Federated Learning Setup**:\n",
    "   - `create_fake_model`: This function creates a model with either a normal learning rate (`0.001`) or an extremely high learning rate (`10.0`) to introduce a bug.\n",
    "\n",
    "7. **Simulated Test Data on Server**:\n",
    "   - `server_test_data` and `server_test_labels`: These are simulated test data and labels used for evaluation.\n",
    "\n",
    "8. **Simulated Client Models**:\n",
    "   - `client_models`: This list contains models for 10 clients, with the first client having a bug (extremely high learning rate).\n",
    "\n",
    "9. **Print Learning Rates of Each Client Model**:\n",
    "   - This loop prints the learning rate of each client model to verify the bug introduction.\n",
    "\n",
    "10. **Train Client Models**:\n",
    "    - This loop trains each client model on the simulated test data.\n",
    "\n",
    "11. **Perform Federated Learning Process**:\n",
    "    - `federated_learning_process`: This function performs the federated learning process, including:\n",
    "      - Predicting with the server model.\n",
    "      - Comparing predictions from client models with the server model using `perform_differential_testing`.\n",
    "      - Storing metrics for each client.\n",
    "      - Detecting outliers using the custom `is_outlier` function.\n",
    "      - Printing a warning if an outlier (potential bug) is detected.\n",
    "\n",
    "In summary, this code sets up a federated learning environment, introduces a bug in one of the client models, and uses differential testing and a custom DBSCAN-like approach to detect the bug before updating the server model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation using the `perform_differential_testing` function is a comparison between each client model and the server model. Here's a breakdown of how it works:\n",
    "\n",
    "1. **Server Model Predictions**:\n",
    "   - The server model makes predictions on the test data (`server_predictions`).\n",
    "\n",
    "2. **Client Model Predictions**:\n",
    "   - Each client model makes predictions on the same test data (`client_predictions`).\n",
    "\n",
    "3. **Comparison**:\n",
    "   - The `perform_differential_testing` function compares the predictions from each client model (`client_predictions`) with the predictions from the server model (`server_predictions`).\n",
    "   - This comparison calculates several metrics:\n",
    "     - `Δ_class`: The number of times the predicted classes differ between the server model and the client model.\n",
    "     - `Δ_score`: The sum of differences in prediction scores between the server model and the client model.\n",
    "     - `P_KS`: The p-value from the Kolmogorov-Smirnov test comparing the distributions of the predictions from the server model and the client model.\n",
    "     - `P_X2`: The p-value from the chi-squared test comparing the contingency table of predicted classes from the server model and the client model.\n",
    "\n",
    "4. **Outlier Detection**:\n",
    "   - The metrics for each client model are stored in `metrics_data`.\n",
    "   - The `is_outlier` function is used to detect outliers in the `metrics_data`, identifying any client models that significantly deviate from the server model.\n",
    "\n",
    "In summary, the evaluation is a comparison between each client model and the server model to detect any significant deviations that might indicate a bug in the client model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0 learning rate: 10.0\n",
      "Client 1 learning rate: 0.0010000000474974513\n",
      "Client 2 learning rate: 0.0010000000474974513\n",
      "Client 3 learning rate: 0.0010000000474974513\n",
      "Client 4 learning rate: 0.0010000000474974513\n",
      "Client 5 learning rate: 0.0010000000474974513\n",
      "Client 6 learning rate: 0.0010000000474974513\n",
      "Client 7 learning rate: 0.0010000000474974513\n",
      "Client 8 learning rate: 0.0010000000474974513\n",
      "Client 9 learning rate: 0.0010000000474974513\n",
      "Warning: Client 0 is an outlier. Potential bug detected.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.stats import ks_2samp, chi2_contingency\n",
    "\n",
    "# Define the metrics function\n",
    "def perform_differential_testing(predictions_i, predictions_j, labels, data_type):\n",
    "    if predictions_i.ndim == 1:\n",
    "        predictions_i = np.expand_dims(predictions_i, axis=1)\n",
    "    if predictions_j.ndim == 1:\n",
    "        predictions_j = np.expand_dims(predictions_j, axis=1)\n",
    "    \n",
    "    pred_class_i = np.argmax(predictions_i, axis=1)\n",
    "    pred_class_j = np.argmax(predictions_j, axis=1)\n",
    "    \n",
    "    Δ_class = np.sum(pred_class_i != pred_class_j)\n",
    "    Δ_score = np.sum(predictions_i != predictions_j)\n",
    "    P_KS = ks_2samp(predictions_i.flatten(), predictions_j.flatten()).pvalue\n",
    "    contingency = np.array([[np.sum((pred_class_i == k) & (pred_class_j == l)) for l in range(10)] for k in range(10)])\n",
    "    contingency += 1  # Add-one smoothing\n",
    "    P_X2 = chi2_contingency(contingency)[1]\n",
    "\n",
    "    return Δ_class, Δ_score, P_KS, P_X2\n",
    "\n",
    "# Custom function to determine if a model is an outlier\n",
    "def is_outlier(metric_data, epsilon=0.1, min_samples=3):  # Modified parameters\n",
    "    num_points = metric_data.shape[0]\n",
    "    distances = np.linalg.norm(metric_data[:, np.newaxis] - metric_data, axis=2)\n",
    "    neighbors = np.sum(distances < epsilon, axis=1)\n",
    "    outliers = neighbors < min_samples\n",
    "    return outliers\n",
    "\n",
    "# Create a simple model\n",
    "def create_model():\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(10, activation='softmax', input_shape=(20,))\n",
    "    ])\n",
    "\n",
    "# Create a federated learning process\n",
    "def model_fn():\n",
    "    model = create_model()\n",
    "    return tff.learning.from_keras_model(\n",
    "        model,\n",
    "        input_spec=(tf.TensorSpec(shape=[None, 20], dtype=tf.float32),\n",
    "                    tf.TensorSpec(shape=[None], dtype=tf.int32)),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "# Simulated federated learning setup\n",
    "def create_fake_model(bug=False):\n",
    "    model = create_model()\n",
    "    if bug:\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=10.0)  # Extremely high learning rate\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)  # Normal learning rate\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Simulated test data on server\n",
    "server_test_data = np.random.random((100, 20))  # 100 samples, 20 features each\n",
    "server_test_labels = np.random.randint(0, 10, 100)  # 100 labels for 10 classes\n",
    "\n",
    "# Simulated client models\n",
    "client_models = [create_fake_model(bug=(i == 0)) for i in range(10)]  # Introduce bug in the first client\n",
    "\n",
    "# Print learning rates of each client model\n",
    "for i, client_model in enumerate(client_models):\n",
    "    print(f\"Client {i} learning rate: {client_model.optimizer.learning_rate.numpy()}\")\n",
    "\n",
    "# Train client models\n",
    "for client_model in client_models:\n",
    "    client_model.fit(server_test_data, server_test_labels, epochs=1, verbose=0)\n",
    "\n",
    "# Perform federated learning process\n",
    "def federated_learning_process(server_model, client_data, epsilon=0.1, min_samples=3):  # Modified parameters\n",
    "    server_predictions = server_model.predict(server_test_data)\n",
    "    server_predictions = np.argmax(server_predictions, axis=1)\n",
    "\n",
    "    # Store metrics for all clients\n",
    "    metrics_data = []\n",
    "\n",
    "    for client_id, client_model in enumerate(client_data):\n",
    "        client_predictions = client_model.predict(server_test_data)\n",
    "        if client_predictions.ndim == 1:\n",
    "            client_predictions = np.expand_dims(client_predictions, axis=1)\n",
    "        client_predictions = np.argmax(client_predictions, axis=1)  # Ensure correct dimensions\n",
    "        Δ_class, Δ_score, P_KS, P_X2 = perform_differential_testing(\n",
    "            server_predictions, client_predictions, server_test_labels, f\"Client {client_id}\"\n",
    "        )\n",
    "        metrics_data.append([Δ_class, Δ_score, P_KS, P_X2])\n",
    "\n",
    "    # Convert metrics data to numpy array\n",
    "    metrics_data = np.array(metrics_data)\n",
    "    \n",
    "    # Check for outliers\n",
    "    outliers = is_outlier(metrics_data, epsilon=epsilon, min_samples=min_samples)\n",
    "    \n",
    "    for i, outlier in enumerate(outliers):\n",
    "        if outlier:\n",
    "            print(f\"Warning: Client {i} is an outlier. Potential bug detected.\")\n",
    "            return  # Stop the process if an outlier is detected\n",
    "\n",
    "# Perform federated learning process\n",
    "federated_learning_process(server_model=create_fake_model(), client_data=client_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using Mnist to implement the federated process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0 learning rate: 10.0\n",
      "Client 1 learning rate: 0.0010000000474974513\n",
      "Client 2 learning rate: 0.0010000000474974513\n",
      "Client 3 learning rate: 0.0010000000474974513\n",
      "Client 4 learning rate: 0.0010000000474974513\n",
      "Client 5 learning rate: 0.0010000000474974513\n",
      "Client 6 learning rate: 0.0010000000474974513\n",
      "Client 7 learning rate: 0.0010000000474974513\n",
      "Client 8 learning rate: 0.0010000000474974513\n",
      "Client 9 learning rate: 0.0010000000474974513\n",
      "Warning: Client 0 is an outlier. Potential bug detected.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.stats import ks_2samp, chi2_contingency\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Define the metrics function\n",
    "def perform_differential_testing(predictions_i, predictions_j, labels, data_type):\n",
    "    if predictions_i.ndim == 1:\n",
    "        predictions_i = np.expand_dims(predictions_i, axis=1)\n",
    "    if predictions_j.ndim == 1:\n",
    "        predictions_j = np.expand_dims(predictions_j, axis=1)\n",
    "    \n",
    "    pred_class_i = np.argmax(predictions_i, axis=1)\n",
    "    pred_class_j = np.argmax(predictions_j, axis=1)\n",
    "    \n",
    "    Δ_class = np.sum(pred_class_i != pred_class_j)\n",
    "    Δ_score = np.sum(predictions_i != predictions_j)\n",
    "    P_KS = ks_2samp(predictions_i.flatten(), predictions_j.flatten()).pvalue\n",
    "    contingency = np.array([[np.sum((pred_class_i == k) & (pred_class_j == l)) for l in range(10)] for k in range(10)])\n",
    "    contingency += 1  # Add-one smoothing\n",
    "    P_X2 = chi2_contingency(contingency)[1]\n",
    "\n",
    "    return Δ_class, Δ_score, P_KS, P_X2\n",
    "\n",
    "# Custom function to determine if a model is an outlier\n",
    "def is_outlier(metric_data, epsilon=0.1, min_samples=3):  # Modified parameters\n",
    "    num_points = metric_data.shape[0]\n",
    "    distances = np.linalg.norm(metric_data[:, np.newaxis] - metric_data, axis=2)\n",
    "    neighbors = np.sum(distances < epsilon, axis=1)\n",
    "    outliers = neighbors < min_samples\n",
    "    return outliers\n",
    "\n",
    "# Create a simple model\n",
    "def create_model():\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "# Create a federated learning process\n",
    "def model_fn():\n",
    "    model = create_model()\n",
    "    return tff.learning.from_keras_model(\n",
    "        model,\n",
    "        input_spec=(tf.TensorSpec(shape=[None, 28, 28], dtype=tf.float32),\n",
    "                    tf.TensorSpec(shape=[None], dtype=tf.int32)),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "# Simulated federated learning setup\n",
    "def create_fake_model(bug=False):\n",
    "    model = create_model()\n",
    "    if bug:\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=10.0)  # Extremely high learning rate\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)  # Normal learning rate\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Load and preprocess MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Simulated client models\n",
    "client_models = [create_fake_model(bug=(i == 0)) for i in range(10)]  # Introduce bug in the first client\n",
    "\n",
    "# Print learning rates of each client model\n",
    "for i, client_model in enumerate(client_models):\n",
    "    print(f\"Client {i} learning rate: {client_model.optimizer.learning_rate.numpy()}\")\n",
    "\n",
    "# Train client models\n",
    "for client_model in client_models:\n",
    "    client_model.fit(train_images, train_labels, epochs=1, verbose=0)\n",
    "\n",
    "# Perform federated learning process\n",
    "def federated_learning_process(server_model, client_data, epsilon=0.1, min_samples=3):  # Modified parameters\n",
    "    server_predictions = server_model.predict(test_images)\n",
    "    server_predictions = np.argmax(server_predictions, axis=1)\n",
    "\n",
    "    # Store metrics for all clients\n",
    "    metrics_data = []\n",
    "\n",
    "    for client_id, client_model in enumerate(client_data):\n",
    "        client_predictions = client_model.predict(test_images)\n",
    "        if client_predictions.ndim == 1:\n",
    "            client_predictions = np.expand_dims(client_predictions, axis=1)\n",
    "        client_predictions = np.argmax(client_predictions, axis=1)  # Ensure correct dimensions\n",
    "        Δ_class, Δ_score, P_KS, P_X2 = perform_differential_testing(\n",
    "            server_predictions, client_predictions, test_labels, f\"Client {client_id}\"\n",
    "        )\n",
    "        metrics_data.append([Δ_class, Δ_score, P_KS, P_X2])\n",
    "\n",
    "    # Convert metrics data to numpy array\n",
    "    metrics_data = np.array(metrics_data)\n",
    "    \n",
    "    # Check for outliers\n",
    "    outliers = is_outlier(metrics_data, epsilon=epsilon, min_samples=min_samples)\n",
    "    \n",
    "    for i, outlier in enumerate(outliers):\n",
    "        if outlier:\n",
    "            print(f\"Warning: Client {i} is an outlier. Potential bug detected.\")\n",
    "            return  # Stop the process if an outlier is detected\n",
    "\n",
    "# Perform federated learning process\n",
    "federated_learning_process(server_model=create_fake_model(), client_data=client_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_fed_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
